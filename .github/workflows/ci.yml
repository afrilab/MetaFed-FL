name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  release:
    types: [ published ]

env:
  PYTHON_VERSION: "3.9"

jobs:
  # Linting and Code Quality
  lint:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements-dev.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
    
    - name: Run black (code formatting)
      run: |
        black --check --diff src/ tests/
    
    - name: Run isort (import sorting)
      run: |
        isort --check-only --diff src/ tests/
    
    - name: Run flake8 (linting)
      run: |
        flake8 src/ tests/ --max-line-length=88 --extend-ignore=E203,W503
    
    - name: Run mypy (type checking)
      run: |
        mypy src/metafed --ignore-missing-imports
      continue-on-error: true  # Type checking is optional for now

  # Unit Tests
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.9", "3.10", "3.11"]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-${{ matrix.python-version }}-pip-${{ hashFiles('**/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-${{ matrix.python-version }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
        pip install -e .
    
    - name: Run unit tests
      run: |
        pytest tests/unit/ -v --cov=src/metafed --cov-report=xml --cov-report=term
    
    - name: Upload coverage to Codecov
      if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.9'
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  # Integration Tests
  integration-test:
    runs-on: ubuntu-latest
    needs: [lint, test]
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
        pip install -e .
    
    - name: Run integration tests
      run: |
        pytest tests/integration/ -v --maxfail=3
      env:
        PYTEST_TIMEOUT: 300  # 5 minutes timeout for integration tests

  # Security Scan
  security:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install safety
      run: |
        python -m pip install --upgrade pip
        pip install safety bandit
    
    - name: Run safety check (dependency vulnerabilities)
      run: |
        safety check
      continue-on-error: true
    
    - name: Run bandit (security linting)
      run: |
        bandit -r src/ -f json -o bandit-report.json
      continue-on-error: true
    
    - name: Upload bandit report
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: bandit-report
        path: bandit-report.json

  # Build and Test Package
  build:
    runs-on: ubuntu-latest
    needs: [lint, test]
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install build dependencies
      run: |
        python -m pip install --upgrade pip
        pip install build twine
    
    - name: Build package
      run: |
        python -m build
    
    - name: Check package
      run: |
        twine check dist/*
    
    - name: Upload build artifacts
      uses: actions/upload-artifact@v3
      with:
        name: dist-packages
        path: dist/

  # Documentation Build
  docs:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
        pip install -e .
    
    - name: Build documentation
      run: |
        # Create docs structure if it doesn't exist
        mkdir -p docs/source
        echo "# MetaFed-FL Documentation" > docs/source/index.md
        echo "Documentation build successful"
      # In a real setup, you would use Sphinx:
      # cd docs && make html
    
    - name: Upload documentation
      uses: actions/upload-artifact@v3
      with:
        name: documentation
        path: docs/

  # Benchmark Tests (Optional)
  benchmark:
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    needs: [test]
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
        pip install -e .
    
    - name: Run benchmarks
      run: |
        # Run simple benchmark tests
        python -c "
        import time
        import torch
        from metafed.models.simple_cnn import SimpleCNN
        
        print('Running basic performance benchmark...')
        model = SimpleCNN()
        data = torch.randn(32, 1, 28, 28)
        
        start_time = time.time()
        for _ in range(100):
            _ = model(data)
        end_time = time.time()
        
        print(f'Model inference time: {(end_time - start_time)/100:.4f}s per batch')
        print('Benchmark completed successfully')
        "

  # Release (only on release events)
  release:
    runs-on: ubuntu-latest
    if: github.event_name == 'release'
    needs: [lint, test, integration-test, build]
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Download build artifacts
      uses: actions/download-artifact@v3
      with:
        name: dist-packages
        path: dist/
    
    - name: Publish to PyPI
      env:
        TWINE_USERNAME: __token__
        TWINE_PASSWORD: ${{ secrets.PYPI_API_TOKEN }}
      run: |
        pip install twine
        twine upload dist/*
      if: github.repository == 'username/MetaFed-FL'  # Only for main repo

  # Notification
  notify:
    runs-on: ubuntu-latest
    if: always()
    needs: [lint, test, integration-test, build]
    steps:
    - name: Notify on success
      if: ${{ needs.lint.result == 'success' && needs.test.result == 'success' && needs.integration-test.result == 'success' && needs.build.result == 'success' }}
      run: echo "✅ All checks passed successfully!"
    
    - name: Notify on failure
      if: ${{ needs.lint.result == 'failure' || needs.test.result == 'failure' || needs.integration-test.result == 'failure' || needs.build.result == 'failure' }}
      run: echo "❌ Some checks failed. Please review the logs."